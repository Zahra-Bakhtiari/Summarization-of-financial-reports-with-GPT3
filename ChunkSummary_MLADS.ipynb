{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization of financial reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: use various Azure OpenAI engines in Zero shot setup to generate summaries of financial reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer.six in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (20221105)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from pdfminer.six) (38.0.3)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from pdfminer.six) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from pdfminer.six) (2.1.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\zabakhti.REDMOND.000\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    !pip install pdfminer.six\n",
    "    import openai\n",
    "except ModuleNotFoundError:\n",
    "    !pip install openai\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: num2words in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (0.5.12)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\zabakhti.redmond.000\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from num2words) (0.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\zabakhti.REDMOND.000\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install num2words\n",
    "import re\n",
    "import requests\n",
    "from num2words import num2words\n",
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and setting attributes for Azure Open AI endpoint\n",
    "\n",
    "The instructors will provide the endpoint URL and key from their Azure OpenAI portal. Add them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"\" # Locate the Endpoint URL in the Azure OpenAI portal and add it here\n",
    "openai.api_key = \"\" # Add provided api key here\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =  \"2022-03-01-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Although here we are explicitly specifying the endpoint and the key, in real-world deployments, it is strongly suggested to use key vault and AAD based authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of summaries approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT3 has a token limit of 2048 - which means that the prompt and completion together cannot exceed 2048 tokens. \n",
    "\n",
    "For summarizing text documents that are longer than 2048 tokens, we use a summary of summaries approach. It consists of 2 stages as explained below:\n",
    "\n",
    "<b>Stage 1</b>\n",
    "\n",
    "The combined text extracted from the PDF is broken down into smaller sub-documents and all of them are summarized individually.\n",
    "\n",
    "<b>Stage 2</b>\n",
    "\n",
    "The summaries generated in Stage 1 are appended together and this is summarized again.\n",
    "\n",
    "\n",
    "Note: The token limit has been increased to 4096 for the 002 series of Instruct model (aka GPT3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text scraped from the PDF into shorter sub-documents that fit within the token limit\n",
    "def splitter(n, s):\n",
    "    pieces = s.split()\n",
    "    list_out = [\" \".join(pieces[i:i+n]) for i in range(0, len(pieces), n)]\n",
    "    return list_out\n",
    "\n",
    "# Data cleaning\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    # remove all instances of multiple spaces\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    # remove specific replacements to curb discrepancies, if any, in the text content\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    return s\n",
    "\n",
    "def trim_incomplete(t):\n",
    "    if t.endswith('.'):\n",
    "        if not re.search('[a-z]\\.$',t):\n",
    "            t = t[:-1]\n",
    "\n",
    "    if not t.endswith('.'):\n",
    "        t = t.rsplit('. ', 1)[:-1]\n",
    "        t = \"\".join(t)+'.'\n",
    "    \n",
    "    t = t.strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to summarize a real-world financial document.\n",
    "\n",
    "We are summarizing the document at this URL: https://www.rathbones.com/sites/rathbones.com/files/imce/rathbones_2020_preliminary_results_announcement_-_final-.pdf\n",
    "\n",
    "Go ahead and checkout the report by clicking on the link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of financial report to be summarized\n",
    "url = \"https://www.rathbones.com/sites/rathbones.com/files/imce/rathbones_2020_preliminary_results_announcement_-_final-.pdf\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please go ahead and use a file handler to write the contents of the above request into a local document called 'report.pdf'\n",
    "\n",
    "Hint: Use open() with 'wb' parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert code here\n",
    "with open(\"report.pdf\",\"wb\") as f:\n",
    "\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the directory to read the local document from\n",
    "name = os.path.abspath(os.path.join(os.getcwd(), 'report.pdf')).replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we only want to summarize the first page of the PDF that has the relevant page that has a broad level description of financial performance for the year 2020. We specify the page indices below. However, it can be extended to cover more pages as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfms_pages = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer_wrapper(engine_name, name, pdfms_pages):\n",
    "    \"\"\"A wrapper function around the summary of summaries completion calls\n",
    "\n",
    "    Args:\n",
    "        engine_name (str): Deployment name from Azure OpenAI portal\n",
    "        name (str): Path to the pdf file\n",
    "        pdfms_pages (list): Indices of the pages to be summarized in the PDF (starting from 0)\n",
    "\n",
    "    Returns:\n",
    "        str: Summary of the long document\n",
    "    \"\"\"\n",
    "    text = extract_text(name\n",
    "    , page_numbers=pdfms_pages\n",
    "    )\n",
    "\n",
    "    r = splitter(200, text)\n",
    "\n",
    "    # The token limit of GPT3 is 2048.\n",
    "    # We approximate it and find the total no. of summaries we can have in Stage 1 of summaries.\n",
    "    # We use this to dynamically control the length of the generated summaries in Stage 1\n",
    "    tok_l = int(2000/len(r))\n",
    "\n",
    "    # Adding max_tokens to prompt as words\n",
    "    tok_l_w = num2words(tok_l)\n",
    "\n",
    "    res_lis = []\n",
    "\n",
    "\n",
    "    # Stage 1\n",
    "    # The sub-documents of the PDF are summarized here\n",
    "    # The nature of summaries is controlled by the prompt, hyperparameters and engine\n",
    "    for i in range(len(r)):\n",
    "        prompt_i = f'Extract and summarize the key financial numbers and percentages mentioned in the Text in less than {tok_l_w} words.\\n\\nText:\\n'+normalize_text(r[i])+'\\n\\nSummary in one paragraph:'\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine_name,\n",
    "            prompt = prompt_i,\n",
    "            temperature = 0,\n",
    "            max_tokens = tok_l,\n",
    "            top_p = 1.0,\n",
    "            frequency_penalty=0.5,\n",
    "            presence_penalty = 0.5,\n",
    "            best_of = 1\n",
    "        )\n",
    "        t = response.choices[0].text\n",
    "        \n",
    "        t = trim_incomplete(t)\n",
    "        res_lis.append(t)\n",
    "\n",
    "\n",
    "\n",
    "    # Stage 2\n",
    "    # The summaries generated above are stored in Python list res_lis\n",
    "    # The sub-document summaries are concatenated into a string and passed to the Completions endpoint\n",
    "    prompt_i = 'Summarize the financial performance of the business like revenue, profit, etc. in less than one hundred words. Do not make up values that are not mentioned in the Text.\\n\\nText:\\n'+\" \".join([normalize_text(res) for res in res_lis])+'\\n\\nSummary:\\n'\n",
    "    response = openai.Completion.create(\n",
    "            engine=engine_name,\n",
    "            prompt = prompt_i,\n",
    "            temperature = 0,\n",
    "            max_tokens = 200,\n",
    "            top_p = 1.0,\n",
    "            frequency_penalty=0.5,\n",
    "            presence_penalty = 0.5,\n",
    "            best_of = 1\n",
    "        )\n",
    "\n",
    "    return trim_incomplete(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GPT3 with Curie engine\n",
    "\n",
    "Instructors will provide you with the engine names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rathbones reported strong financial performance in 2020, with FUMA growing by 8.5% and underlying profit before tax increasing by 4.3%. The company also reported profits before tax of £43.8 million, up 5.2% from the previous year. The company reported an increase in operating income and earnings per share, as well as a declaration of final dividend.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add the engine name as first argument\n",
    "summarizer_wrapper(\"curie\", name, pdfms_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at summarization with Da vinci Instruct with GPT3 and GPT3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity: Using GPT3 with Da Vinci engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rathbones delivered a strong performance in 2020, with funds under management and administration (FUMA) growing by 8.5% to reach £54.7 billion at the end of the year. Underlying profit before tax increased by 4.3% to £92.5 million, delivering an underlying operating margin of 25.3%. Total net inflows across the group were £2.1 billion, representing a growth rate of 4.2%. Profit before tax for the year was £43.8 million, with basic earnings per share totalling 49.6p. Operating income for the year was 5.2% ahead of the prior year, totalling £366.1 million.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Insert code here\n",
    "summarizer_wrapper(\"davinci\", name, pdfms_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity: Using GPT3.5 with Da Vinci engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rathbones delivered a strong performance in 2020, with funds under management and administration (FUMA) growing by 8.5% to reach £54.7 billion at the end of the year. Underlying profit before tax increased by 4.3% to £92.5 million, delivering an underlying operating margin of 25.3%. Total net inflows across the group were £2.1 billion, representing a growth rate of 4.2%. Profit before tax for the year was £43.8 million, with basic earnings per share totalling 49.6p. Operating income for the year was 5.2% ahead of the prior year, totalling £366.1 million.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Insert code here\n",
    "summarizer_wrapper(\"davinci\", name, pdfms_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters specified above were found to give good performance for the summarization task in question. Feel free to play around with the hyperparameters and see how the completions change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity: Go ahead and try to summarize the first five pages instead of just the first page and see how the generated summaries are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 pages summarization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bb392c1ffa9b58b699db08fabefa1abac5b78f7e85926fa8c6bd06f72937e96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
